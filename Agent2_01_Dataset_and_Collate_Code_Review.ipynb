{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad1a55a",
   "metadata": {},
   "source": [
    "# Agent 2 — Module Walkthrough (Code + Review)\n",
    "## Dataset & Collate (`dataset.py`)\n",
    "\n",
    "**Author:** Summer Xiong  \n",
    "**Goal:** Explain *exactly* what this module does, step-by-step, with shapes, inputs/outputs, and review notes.\n",
    "\n",
    "This module defines:\n",
    "- `EncodedWindow` (dataclass): a single **encoded training example**  \n",
    "- `WindowDataset` (PyTorch `Dataset`): converts raw window objects into tensors  \n",
    "- `collate_fn`: batches samples into model-ready tensors\n",
    "\n",
    "> **Key idea:** Each sample is a **window of W steps**. Each step has:\n",
    "> - a **text** (tokenised into length `L`)\n",
    "> - a **numeric feature vector** (size `F`)\n",
    "> And the sample has a **single label** (classification target).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ceaf94",
   "metadata": {},
   "source": [
    "## 0) Environment & Dependencies\n",
    "\n",
    "This notebook uses:\n",
    "- `pandas`, `numpy` — data loading/processing  \n",
    "- `scikit-learn` — scaling, KMeans clustering, silhouette score, PCA  \n",
    "- `matplotlib` — static plots  \n",
    "- `plotly` (optional) — radar charts for cluster profiles  \n",
    "- `dataframe_image` (optional) — export styled tables as PNG\n",
    "\n",
    "> Note: This particular module (`dataset.py`) primarily depends on **PyTorch** + **NumPy**.  \n",
    "> The extra libraries above are mentioned because they are used elsewhere in Agent 2/Agent 1 notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a662cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34235f4",
   "metadata": {},
   "source": [
    "## 1) `EncodedWindow` Dataclass\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class EncodedWindow:\n",
    "    input_ids: torch.Tensor        # (W, L)\n",
    "    attention_mask: torch.Tensor   # (W, L)\n",
    "    num_feats: torch.Tensor        # (W, F)\n",
    "    label: int                     # scalar\n",
    "    voter_id: str\n",
    "    cluster_id: int\n",
    "```\n",
    "\n",
    "### What it represents\n",
    "One training example after preprocessing/encoding.\n",
    "\n",
    "### Shapes\n",
    "- `W` = number of steps in the window (sequence length at window level)\n",
    "- `L` = token length per step (e.g., 128)\n",
    "- `F` = number of numeric features per step\n",
    "\n",
    "### Why keep `voter_id` and `cluster_id`?\n",
    "- `voter_id`: traceability / debugging / per-voter analysis  \n",
    "- `cluster_id`: supports **cluster-conditional evaluation** or **cluster-specific heads** later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179310dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EncodedWindow:\n",
    "    input_ids: torch.Tensor        # (W, L)\n",
    "    attention_mask: torch.Tensor   # (W, L)\n",
    "    num_feats: torch.Tensor        # (W, F)\n",
    "    label: int                     # scalar\n",
    "    voter_id: str\n",
    "    cluster_id: int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512973d",
   "metadata": {},
   "source": [
    "## 2) `WindowDataset`: turning raw windows into tensors\n",
    "\n",
    "### Purpose\n",
    "`WindowDataset` takes a list of raw window objects and a tokenizer and outputs `EncodedWindow`.\n",
    "\n",
    "### Expected interface of each raw window object `w`\n",
    "Your code assumes each `w` has the following attributes:\n",
    "\n",
    "- `w.window_texts`: `List[str]` of length `W`  \n",
    "- `w.window_features`: list/array shaped `(W, F)`  \n",
    "- `w.target_label`: int-like (class id)  \n",
    "- `w.voter_id`: string id  \n",
    "- `w.cluster_id`: int-like\n",
    "\n",
    "If any of these are missing or have inconsistent lengths, training will break at runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, windows: List[Any], tokenizer, max_length: int = 128):\n",
    "        self.windows = windows\n",
    "        self.tok = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.windows)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> EncodedWindow:\n",
    "        w = self.windows[idx]\n",
    "        # Encode each step text separately\n",
    "        ids, masks = [], []\n",
    "        for t in w.window_texts:\n",
    "            enc = self.tok(\n",
    "                t,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            ids.append(enc[\"input_ids\"][0])          # (L,)\n",
    "            masks.append(enc[\"attention_mask\"][0])   # (L,)\n",
    "        input_ids = torch.stack(ids, dim=0)          # (W, L)\n",
    "        attention_mask = torch.stack(masks, dim=0)   # (W, L)\n",
    "        # Numeric features\n",
    "        num_feats = torch.tensor(np.stack(w.window_features, axis=0), dtype=torch.float32)  # (W, F)\n",
    "        return EncodedWindow(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            num_feats=num_feats,\n",
    "            label=int(w.target_label),\n",
    "            voter_id=w.voter_id,\n",
    "            cluster_id=int(w.cluster_id)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0133d",
   "metadata": {},
   "source": [
    "### 2.1 Step-by-step inside `__getitem__`\n",
    "\n",
    "#### (A) Tokenise each step text independently\n",
    "For each step text `t` in `w.window_texts`, the tokenizer returns:\n",
    "- `input_ids`: shape `(1, L)`\n",
    "- `attention_mask`: shape `(1, L)`\n",
    "\n",
    "Then `[0]` removes the batch dimension and keeps `(L,)`.\n",
    "\n",
    "#### (B) Stack over window steps\n",
    "`torch.stack(ids, dim=0)` gives:\n",
    "- `input_ids`: `(W, L)`\n",
    "- `attention_mask`: `(W, L)`\n",
    "\n",
    "#### (C) Numeric features\n",
    "`np.stack(w.window_features, axis=0)` forms `(W, F)` then converted to `torch.float32`.\n",
    "\n",
    "#### (D) Return EncodedWindow\n",
    "A single encoded sample with tensors + metadata.\n",
    "\n",
    "---\n",
    "\n",
    "### Review notes (important)\n",
    "✅ Strengths\n",
    "- Clear and consistent tensor shapes\n",
    "- Keeps metadata (`voter_id`, `cluster_id`) for later analysis\n",
    "- Clean separation of text and numeric features\n",
    "\n",
    "⚠️ Potential issues / improvements\n",
    "1) **Padding strategy**: `padding=\"max_length\"` pads every step to `L` (simple but wasteful).\n",
    "   - Consider **dynamic padding** at batch time for better efficiency.\n",
    "2) **Tokenisation cost**: tokenising in `__getitem__` repeats work each epoch.\n",
    "   - Consider caching or pre-tokenising if the dataset is large.\n",
    "3) **Type/shape checks**: if `len(window_texts) != len(window_features)`, tensors misalign.\n",
    "   - Add assertions to catch errors early.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc3f1d",
   "metadata": {},
   "source": [
    "## 3) `collate_fn`: batching samples for the model\n",
    "\n",
    "### Purpose\n",
    "PyTorch `DataLoader` uses `collate_fn` to combine a list of samples into a batch.\n",
    "\n",
    "### Input\n",
    "A list of `EncodedWindow` objects of length `B` (batch size).\n",
    "\n",
    "### Output dictionary (model-ready)\n",
    "- `input_ids`: `(B, W, L)`\n",
    "- `attention_mask`: `(B, W, L)`\n",
    "- `num_feats`: `(B, W, F)`\n",
    "- `labels`: `(B,)`\n",
    "- `clusters`: `(B,)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30989a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: List[EncodedWindow]) -> Dict[str, torch.Tensor]:\n",
    "    input_ids = torch.stack([b.input_ids for b in batch], dim=0)            # (B, W, L)\n",
    "    attention_mask = torch.stack([b.attention_mask for b in batch], dim=0)  # (B, W, L)\n",
    "    num_feats = torch.stack([b.num_feats for b in batch], dim=0)            # (B, W, F)\n",
    "    labels = torch.tensor([b.label for b in batch], dtype=torch.long)       # (B,)\n",
    "    clusters = torch.tensor([b.cluster_id for b in batch], dtype=torch.long)\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"num_feats\": num_feats,\n",
    "        \"labels\": labels,\n",
    "        \"clusters\": clusters\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11e540",
   "metadata": {},
   "source": [
    "### Review notes (collate_fn)\n",
    "\n",
    "✅ Strengths\n",
    "- Straightforward stacking and clear shapes\n",
    "- Returns a dict (fits most training loops)\n",
    "- Keeps `clusters` for segmentation-aware metrics\n",
    "\n",
    "⚠️ Improvements\n",
    "- If you adopt **dynamic padding**, implement it here.\n",
    "- If you want per-voter error analysis, you may also return `voter_id` here (currently dropped).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bcc133",
   "metadata": {},
   "source": [
    "## 4) Minimal Sanity Check (No Transformers Required)\n",
    "\n",
    "We create:\n",
    "- a dummy window object with the required fields\n",
    "- a dummy tokenizer that mimics the `transformers` interface\n",
    "\n",
    "This lets you validate output shapes without installing HF transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f8f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "class DummyTokenizer:\n",
    "    def __call__(self, text, truncation=True, max_length=8, padding=\"max_length\", return_tensors=\"pt\"):\n",
    "        # Simple fake tokeniser: map each character to an int, then truncate/pad\n",
    "        ids = [min(ord(c), 255) for c in text][:max_length]\n",
    "        ids = ids + [0] * (max_length - len(ids))\n",
    "        attn = [1 if i != 0 else 0 for i in ids]\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor([ids], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor([attn], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "dummy_window = SimpleNamespace(\n",
    "    window_texts=[\"step one\", \"step two\", \"step three\"],     # W=3\n",
    "    window_features=[[0.1, 1.0], [0.2, 0.9], [0.3, 0.8]],    # (W, F) where F=2\n",
    "    target_label=1,\n",
    "    voter_id=\"0xabc\",\n",
    "    cluster_id=2,\n",
    ")\n",
    "\n",
    "ds = WindowDataset([dummy_window], tokenizer=DummyTokenizer(), max_length=8)\n",
    "sample = ds[0]\n",
    "\n",
    "print(\"input_ids:\", sample.input_ids.shape)         # (W, L)\n",
    "print(\"attention_mask:\", sample.attention_mask.shape)\n",
    "print(\"num_feats:\", sample.num_feats.shape)         # (W, F)\n",
    "print(\"label:\", sample.label, \"cluster:\", sample.cluster_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaa3586",
   "metadata": {},
   "source": [
    "## 5) Summary\n",
    "\n",
    "This module ensures Agent 2 training receives:\n",
    "- windowed token ids & masks for text sequences\n",
    "- aligned numeric feature sequences\n",
    "- class labels for supervision\n",
    "- cluster ids for segmentation-aware evaluation or modelling\n",
    "\n",
    "It is a clean, minimal foundation for sequence-based vote prediction models.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
