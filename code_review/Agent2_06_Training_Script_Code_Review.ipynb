{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a15290",
   "metadata": {},
   "source": [
    "# Agent 2 — Module Walkthrough (Code + Review)\n",
    "## Training Script (`train_agent2.py`)\n",
    "\n",
    "**Author:** Summer Xiong  \n",
    "**Goal:** Provide a *research-grade, executable* walkthrough of the Agent 2 training pipeline: data → windows → dataset → model → training loop → validation → artifact saving.\n",
    "\n",
    "This notebook mirrors your training script but adds:\n",
    "- Clear **inputs/outputs** and **tensor shapes**\n",
    "- Methodological rationale (anti-leakage split, windowing, macro metrics)\n",
    "- Review notes (robustness, missing checks, reproducibility)\n",
    "\n",
    "> **Usage (Colab):**\n",
    "> ```bash\n",
    "> !pip -q install -r requirements.txt\n",
    "> !python train_agent2.py --data_dir /content/data --epochs 6 --window 5\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb522290",
   "metadata": {},
   "source": [
    "## 0) Imports & Dependencies\n",
    "\n",
    "This training script depends on Agent 2 modules:\n",
    "- `load_data.py` → ingestion + schema normalisation + split\n",
    "- `windows.py` → sliding window construction\n",
    "- `dataset.py` → tokenisation + collation\n",
    "- `model.py` → TimeSeriesClassifier architecture\n",
    "- `metrics.py` → macro PRF evaluation\n",
    "\n",
    "External dependencies:\n",
    "- PyTorch, Transformers, tqdm, NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31aec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "from load_data import load_and_merge, normalise_columns, select_numeric_columns, split_by_voter, VALID_LABELS\n",
    "from windows import build_windows\n",
    "from dataset import WindowDataset, collate_fn\n",
    "from model import TimeSeriesClassifier\n",
    "from metrics import macro_prf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b2feb",
   "metadata": {},
   "source": [
    "## 1) Utility: Class Weights for Imbalance\n",
    "\n",
    "```python\n",
    "w_c = N / (C * max(count_c, 1))\n",
    "```\n",
    "\n",
    "### What this does\n",
    "Computes inverse-frequency class weights to mitigate class imbalance.\n",
    "\n",
    "### Why it matters in DAO votes\n",
    "FOR is often dominant; AGAINST/ABSTAIN can be sparse.  \n",
    "Weighted loss helps ensure the model does not ignore minority classes.\n",
    "\n",
    "### Review note\n",
    "This is a simple baseline. Alternatives include:\n",
    "- focal loss\n",
    "- effective number of samples (Cui et al.)\n",
    "- per-cluster class weighting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92277329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(y: np.ndarray, num_classes: int = 3) -> torch.Tensor:\n",
    "    counts = np.bincount(y, minlength=num_classes).astype(float)\n",
    "    N = counts.sum()\n",
    "    w = N / (num_classes * np.maximum(counts, 1.0))\n",
    "    return torch.tensor(w, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d820f81",
   "metadata": {},
   "source": [
    "## 2) Argument Parsing and Reproducibility\n",
    "\n",
    "### CLI arguments\n",
    "- `--data_dir`: directory containing `cluster_0/1/2_dataset.csv`\n",
    "- `--pretrained`: HF model name (default `roberta-base`)\n",
    "- window/tokenisation/training hyperparameters\n",
    "\n",
    "### Seeds\n",
    "You set seeds for both PyTorch and NumPy.\n",
    "\n",
    "**Review note:** For stronger determinism consider:\n",
    "- `torch.cuda.manual_seed_all`\n",
    "- `torch.backends.cudnn.deterministic = True` (may affect speed)\n",
    "- logging the full environment (CUDA, transformers version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--data_dir\", type=str, required=True, help=\"Directory containing cluster_0/1/2_dataset.csv\")\n",
    "    ap.add_argument(\"--pretrained\", type=str, default=\"roberta-base\")\n",
    "    ap.add_argument(\"--window\", type=int, default=5)\n",
    "    ap.add_argument(\"--max_length\", type=int, default=128)\n",
    "    ap.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    ap.add_argument(\"--epochs\", type=int, default=6)\n",
    "    ap.add_argument(\"--lr\", type=float, default=2e-5)\n",
    "    ap.add_argument(\"--seed\", type=int, default=42)\n",
    "    return ap.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa447c1",
   "metadata": {},
   "source": [
    "## 3) Data Loading → Normalisation → Label Filtering\n",
    "\n",
    "### Pipeline\n",
    "1. Load `cluster_{0,1,2}_dataset.csv` files\n",
    "2. Concatenate\n",
    "3. Normalise schema (`normalise_columns`)\n",
    "4. Filter to valid labels `{0,1,2}`\n",
    "\n",
    "**Review note:** The script assumes exactly 3 files (clusters 0–2).  \n",
    "If you later change cluster count, parameterise this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8398ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_pipeline(data_dir: Path):\n",
    "    csvs = [data_dir / f\"cluster_{i}_dataset.csv\" for i in range(3)]\n",
    "    df = load_and_merge(csvs)\n",
    "    df = normalise_columns(df)\n",
    "    df = df[df[\"label_id\"].isin([0, 1, 2])].copy()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a619ba8f",
   "metadata": {},
   "source": [
    "## 4) Split by Voter (Anti-Leakage)\n",
    "\n",
    "You split train/valid by **voter** rather than by rows.\n",
    "\n",
    "This is one of the most defensible design choices in the entire pipeline:\n",
    "- prevents identity leakage\n",
    "- yields more realistic generalisation metrics\n",
    "\n",
    "We'll keep it as-is, but we should also verify there is no overlap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ad88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid(df: \"pd.DataFrame\", seed: int = 42):\n",
    "    train_df, valid_df = split_by_voter(df, train_frac=0.8, seed=seed)\n",
    "    overlap = set(train_df[\"voter\"]).intersection(set(valid_df[\"voter\"]))\n",
    "    return train_df, valid_df, len(overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b778593",
   "metadata": {},
   "source": [
    "## 5) Tokeniser with Special Tokens\n",
    "\n",
    "### Why special tokens?\n",
    "Your window builder prefixes texts with:\n",
    "- `[PREDICT]`\n",
    "- `[LABEL_0]`, `[LABEL_1]`, `[LABEL_2]`\n",
    "\n",
    "Adding these tokens ensures the tokenizer treats them as atomic tokens (not split into subword fragments), improving signal clarity.\n",
    "\n",
    "**Implementation detail**\n",
    "After adding tokens, you must call:\n",
    "```python\n",
    "model.text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "```\n",
    "to update the embedding matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4fca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tokenizer(pretrained: str):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained, use_fast=True)\n",
    "    special_tokens = {\"additional_special_tokens\": [\"[PREDICT]\", \"[LABEL_0]\", \"[LABEL_1]\", \"[LABEL_2]\"]}\n",
    "    tokenizer.add_special_tokens(special_tokens)\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d1a25",
   "metadata": {},
   "source": [
    "## 6) Build Windows (Sequence Construction)\n",
    "\n",
    "### What happens here\n",
    "- Choose numeric columns using `select_numeric_columns(df)`\n",
    "- Call `build_windows(...)` on train and valid splits\n",
    "\n",
    "### Output\n",
    "- `train_windows`, `valid_windows`: lists of `Window` objects\n",
    "- Each `Window` contains:\n",
    "  - `window_texts` length `W`\n",
    "  - `window_features` list length `W`, each vector length `F`\n",
    "  - `target_label` ∈ {0,1,2}\n",
    "\n",
    "**Review note:** This step is often the bottleneck (Python loops).  \n",
    "If dataset grows, consider caching windows to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd350c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_windows_for_split(df_part, window_size: int, numeric_cols):\n",
    "    return build_windows(\n",
    "        df=df_part,\n",
    "        window_size=window_size,\n",
    "        text_col=\"text\",\n",
    "        label_col=\"label_id\",\n",
    "        voter_col=\"voter\",\n",
    "        time_col=\"vote_ts\",\n",
    "        cluster_col=\"cluster_id\",\n",
    "        numeric_cols=numeric_cols,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641c341",
   "metadata": {},
   "source": [
    "## 7) Dataset, DataLoader, and Feature Dimension\n",
    "\n",
    "### Dataset\n",
    "`WindowDataset` performs tokenisation per step in `__getitem__`, returning tensors:\n",
    "- `input_ids`: `(W, L)`\n",
    "- `attention_mask`: `(W, L)`\n",
    "- `num_feats`: `(W, F)`\n",
    "\n",
    "### DataLoader / collate_fn\n",
    "Batches into:\n",
    "- `input_ids`: `(B, W, L)`\n",
    "- `attention_mask`: `(B, W, L)`\n",
    "- `num_feats`: `(B, W, F)`\n",
    "- `labels`: `(B,)`\n",
    "\n",
    "### feat_dim inference\n",
    "You infer `feat_dim` using the first window:\n",
    "```python\n",
    "feat_dim = len(train_windows[0].window_features[0])\n",
    "```\n",
    "\n",
    "**Review note:** Add a safety assert to ensure all steps and all windows have the same feature length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7161234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_feat_dim(train_windows, default: int = 8) -> int:\n",
    "    if len(train_windows) == 0:\n",
    "        return default\n",
    "    return int(len(train_windows[0].window_features[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca9f643",
   "metadata": {},
   "source": [
    "## 8) Model Initialisation\n",
    "\n",
    "- Instantiate `TimeSeriesClassifier(pretrained_model_name, feat_dim)`\n",
    "- Resize token embeddings to include special tokens\n",
    "- Move to GPU if available\n",
    "\n",
    "**Review note:** This is correct. Just ensure:\n",
    "- `feat_dim` matches actual numeric vector length from `build_windows`\n",
    "- window size `W` is within position embedding range (`<=512`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained: str, feat_dim: int, tokenizer) -> TimeSeriesClassifier:\n",
    "    model = TimeSeriesClassifier(pretrained_model_name=pretrained, feat_dim=feat_dim)\n",
    "    model.text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24094c77",
   "metadata": {},
   "source": [
    "## 9) Optimiser & Scheduler\n",
    "\n",
    "- Optimiser: `AdamW`\n",
    "- Scheduler: linear warmup (10% steps) then decay\n",
    "\n",
    "This is a standard, defensible setup for transformer fine-tuning.\n",
    "\n",
    "**Review note:** Log `total_steps`, `warmup_steps` for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optim_and_sched(model, lr: float, epochs: int, train_loader_len: int):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    total_steps = train_loader_len * epochs\n",
    "    warmup_steps = int(0.1 * total_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "    return optimizer, scheduler, total_steps, warmup_steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a60a2d",
   "metadata": {},
   "source": [
    "## 10) Training Loop (Epoch → Train → Valid → Best Checkpoint)\n",
    "\n",
    "### Train step\n",
    "- forward\n",
    "- weighted cross-entropy loss\n",
    "- backward + gradient clipping\n",
    "- optimizer step + scheduler step\n",
    "- collect predictions for macro PRF\n",
    "\n",
    "### Valid step\n",
    "- `torch.no_grad()`\n",
    "- collect predictions for macro PRF\n",
    "\n",
    "### Model selection\n",
    "- track best validation F1 (macro)\n",
    "- store best model weights on CPU for safe saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_batch_to_device(batch, device):\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"num_feats\", \"labels\", \"clusters\"]:\n",
    "        batch[k] = batch[k].to(device)\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589c002",
   "metadata": {},
   "source": [
    "### Full training loop (as in script)\n",
    "\n",
    "This cell contains the original loop logic but rewritten into notebook-friendly functions.  \n",
    "You can run this once your data directory is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed5391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent2(args):\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    data_dir = Path(args.data_dir)\n",
    "    df = load_data_pipeline(data_dir)\n",
    "\n",
    "    train_df, valid_df, overlap = split_train_valid(df, seed=args.seed)\n",
    "    print(f\"Train rows: {len(train_df)}, Valid rows: {len(valid_df)}, Voter overlap: {overlap}\")\n",
    "\n",
    "    tokenizer = build_tokenizer(args.pretrained)\n",
    "    numeric_cols = select_numeric_columns(df)\n",
    "\n",
    "    train_windows = build_windows_for_split(train_df, args.window, numeric_cols)\n",
    "    valid_windows = build_windows_for_split(valid_df, args.window, numeric_cols)\n",
    "    print(f\"Train windows: {len(train_windows)}, Valid windows: {len(valid_windows)}\")\n",
    "\n",
    "    train_ds = WindowDataset(train_windows, tokenizer, max_length=args.max_length)\n",
    "    valid_ds = WindowDataset(valid_windows, tokenizer, max_length=args.max_length)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    valid_loader = DataLoader(valid_ds, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    feat_dim = infer_feat_dim(train_windows, default=8)\n",
    "    model = build_model(args.pretrained, feat_dim, tokenizer)\n",
    "\n",
    "    optimizer, scheduler, total_steps, warmup_steps = build_optim_and_sched(\n",
    "        model, args.lr, args.epochs, len(train_loader)\n",
    "    )\n",
    "    print(f\"Total steps: {total_steps}, Warmup steps: {warmup_steps}, feat_dim: {feat_dim}\")\n",
    "\n",
    "    y_train = np.array([w.target_label for w in train_windows], dtype=int)\n",
    "    class_weights = compute_class_weights(y_train).to(next(model.parameters()).device)\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    best_f1, best_state = -1.0, None\n",
    "    for epoch in range(args.epochs):\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        y_true, y_pred = [], []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{args.epochs} [train]\"):\n",
    "            batch = move_batch_to_device(batch, device)\n",
    "            out = model(batch)\n",
    "            loss = model.loss_fn(out[\"logits\"], batch[\"labels\"], class_weights=class_weights)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += float(loss.item())\n",
    "\n",
    "            preds = out[\"logits\"].argmax(dim=-1).detach().cpu().numpy().tolist()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(batch[\"labels\"].detach().cpu().numpy().tolist())\n",
    "\n",
    "        train_metrics = macro_prf(y_true, y_pred)\n",
    "\n",
    "        # ---- valid ----\n",
    "        model.eval()\n",
    "        vy_true, vy_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{args.epochs} [valid]\"):\n",
    "                batch = move_batch_to_device(batch, device)\n",
    "                out = model(batch)\n",
    "                preds = out[\"logits\"].argmax(dim=-1).detach().cpu().numpy().tolist()\n",
    "                vy_pred.extend(preds)\n",
    "                vy_true.extend(batch[\"labels\"].detach().cpu().numpy().tolist())\n",
    "\n",
    "        val_metrics = macro_prf(vy_true, vy_pred)\n",
    "\n",
    "        print(\n",
    "            f\"\\nEpoch {epoch+1}: \"\n",
    "            f\"loss={running_loss/len(train_loader):.4f} \"\n",
    "            f\"train F1={train_metrics['f1']:.4f} | valid F1={val_metrics['f1']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_metrics[\"f1\"] > best_f1:\n",
    "            best_f1 = float(val_metrics[\"f1\"])\n",
    "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "            print(f\"✓ New best model: F1={best_f1:.4f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"Loaded best model with F1={best_f1:.4f}\")\n",
    "\n",
    "    return model, tokenizer, {\"best_f1\": best_f1, \"feat_dim\": feat_dim}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f38560",
   "metadata": {},
   "source": [
    "## 11) Saving Artifacts (Model + Tokeniser + Config)\n",
    "\n",
    "You save to:\n",
    "- `agent2_artifacts/agent2_model.pt` (state dict)\n",
    "- `agent2_artifacts/tokenizer/` (HF tokenizer files)\n",
    "- `agent2_artifacts/config.json` (hyperparameters + best F1)\n",
    "\n",
    "This is good practice for reproducibility and later inference.\n",
    "\n",
    "**Review note:** Consider saving:\n",
    "- `class_weights`\n",
    "- training/validation metrics by epoch\n",
    "- git commit hash / run id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9acdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artifacts(model, tokenizer, run_info: dict, args, outdir: Path = Path(\"agent2_artifacts\")):\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_path = outdir / \"agent2_model.pt\"\n",
    "    tok_path = outdir / \"tokenizer\"\n",
    "    tok_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    tokenizer.save_pretrained(tok_path)\n",
    "\n",
    "    cfg = {\n",
    "        \"pretrained\": args.pretrained,\n",
    "        \"window\": args.window,\n",
    "        \"max_length\": args.max_length,\n",
    "        \"feat_dim\": int(run_info.get(\"feat_dim\", 0)),\n",
    "        \"label_map\": {\"FOR\": 0, \"AGAINST\": 1, \"ABSTAIN\": 2},\n",
    "        \"best_f1\": float(run_info.get(\"best_f1\", -1.0)),\n",
    "    }\n",
    "\n",
    "    with open(outdir / \"config.json\", \"w\") as f:\n",
    "        json.dump(cfg, f, indent=2)\n",
    "\n",
    "    print(f\"Saved model to {model_path} and tokenizer to {tok_path}\")\n",
    "    return model_path, tok_path, outdir / \"config.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2608ccf",
   "metadata": {},
   "source": [
    "## 12) Review Notes: High-Impact Improvements\n",
    "\n",
    "If you want this training pipeline to look **publication-ready / mentor-ready**, the top improvements are:\n",
    "\n",
    "1) **Add explicit checks**\n",
    "- non-empty windows\n",
    "- constant feature dimension across all steps/windows\n",
    "- no NaN labels after normalisation\n",
    "\n",
    "2) **Fix boolean column naming consistency**\n",
    "Your window builder currently reads raw `\"Is Whale\"` columns; normalised schema produces `is_whale`.  \n",
    "Standardise to avoid silently dropping booleans.\n",
    "\n",
    "3) **Add logging**\n",
    "- metrics per epoch (train/valid)\n",
    "- save as JSON/CSV for plotting\n",
    "- store random seed, versions\n",
    "\n",
    "4) **Add per-cluster evaluation**\n",
    "You already pass `clusters` in batch.  \n",
    "Compute macro F1 per cluster to support fairness claims.\n",
    "\n",
    "5) **Make cluster file count configurable**\n",
    "Right now you hardcode 3 cluster CSVs. Parameterise if cluster K changes.\n",
    "\n",
    "These changes are small but will greatly increase the credibility of your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3428aa",
   "metadata": {},
   "source": [
    "## 13) Full Script (Original Reference)\n",
    "\n",
    "For completeness, below is the original training script content (kept as-is).  \n",
    "In practice, you will run the notebook functions for clarity, or run the script for production runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original script reference (verbatim)\n",
    "# NOTE: In the notebook, prefer using the helper functions defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c7cbc",
   "metadata": {},
   "source": [
    "## 14) Summary\n",
    "\n",
    "This training pipeline:\n",
    "- loads and normalises vote data\n",
    "- applies a **voter-wise split** to prevent leakage\n",
    "- builds sliding windows to form a sequence prediction dataset\n",
    "- fine-tunes a multimodal temporal model (text + numeric + temporal transformer)\n",
    "- evaluates with macro PRF\n",
    "- saves reproducible artifacts\n",
    "\n",
    "It is a solid baseline for Agent 2, and with a few robustness additions, it can be presented confidently to supervisors.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
